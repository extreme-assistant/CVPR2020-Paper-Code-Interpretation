# CVPR2021最新信息及论文下载贴（Papers/Codes/Project/PaperReading／Demos/直播分享／论文分享会等）

官网链接：http://cvpr2021.thecvf.com<br>
时间：2021年6月19日-6月25日<br>
论文接收公布时间：2021年2月28日<br>

相关问题：<br>

* [如何评价CVPR 2021的论文接收结果？](https://www.zhihu.com/question/446299297)<br>
* [CVPR 2021接收结果出炉！录用1663篇，接受率提升，你的论文中了吗？（附论文下载）](https://mp.weixin.qq.com/s/4UQ2W1V-eLnL02L8BDOtMg)

<br><br>

# 目录

[1. CVPR2021接受论文/代码分方向汇总（持续更新）](#1)<br>
[2. CVPR2021 Oral](#2)<br>
[3. To do list](#3)<br>


<br>

<a name="1"/> 

# 1.CVPR2021接受论文/代码分方向整理(持续更新)


## 分类目录：

### [1. 检测](#detection)
* [图像目标检测(Image Object Detection)](#IOD)<br>
* [视频目标检测(Video Object Detection)](#VOD)<br>
* [三维目标检测(3D Object Detection)](#3DOD)<br>
* [动作检测(Activity Detection)](#ActivityDetection)<br>
* [异常检测(Anomally Detetion)](#AnomallyDetetion)<br>

### [2. 图像分割(Image Segmentation)](#ImageSegmentation)
* [全景分割(Panoptic Segmentation)](#PanopticSegmentation)<br>
* [语义分割(Semantic Segmentation)](#SemanticSegmentation)<br>
* [实例分割(Instance Segmentation)](#InstanceSegmentation)<br>
* [抠图(Matting)](#Matting)<br>

### [3. 人体姿态估计(Human Pose Estimation)](#HumanPoseEstimation)

### [4. 人脸(Face)](#Face)

### [5. 目标跟踪(Object Tracking)](#ObjectTracking)

### [6. 重识别(Re-Identification)](#Re-Identification)

### [7. 医学影像(Medical Imaging)](#MedicalImaging)

### [8. GAN/生成式/对抗式(GAN/Generative/Adversarial)](#GAN)

### [9. 图像处理(Image Processing)](#ImageProcessing)

* [图像复原(Image Restoration)/超分辨率(Super Resolution)](#ImageRestoration)
* [图像阴影去除(Image Shadow Removal)](#ISR)
* [图像去噪/去模糊/去雨去雾(Image Denoising)](#ImageDenoising)
* [图像编辑(Image Edit)](#ImageEdit)
* [图像翻译(Image Translation)](#ImageTranslation))


### [10. 三维视觉(3D Vision)](#3DVision)
* [三维点云(3D Point Cloud)](#3DPC)<br>
* [三维重建(3D Reconstruction)](#3DReconstruction)<br>

### [11. 神经网络架构(Neural Network Structure)](#NNS)
* [Transformer](#Transformer)<br>
* [图神经网络(GNN)](#GNN)<br>

### [12. 神经网络架构搜索(NAS)](#NAS)

### [13. 数据处理(Data Processing)](#DataProcessing)
* [数据增广(Data Augmentation)](#DataAugmentation)<br>
* [归一化/正则化(Batch Normalization)](#BatchNormalization)<br>
* [图像聚类(Image Clustering)](#ImageClustering)<br>

### [14. 模型压缩(Model Compression)](#ModelCompression)
* [知识蒸馏(Knowledge Distillation)](KnowledgeDistillation)<br>

### [15. 模型评估(Model Evaluation)](#ModelEvaluation)

### [16. 数据集(Database)](#Database)

### [17. 主动学习(Active Learning)](#ActiveLearning)

### [18. 小样本学习/零样本(Few-shot Learning)](#Few-shotLearning)

### [19. 持续学习(Continual Learning/Life-long Learning)](#ContinualLearning)

### [20. 视觉推理(Visual Reasoning)](#VisualReasoning)

### [21. 迁移学习/domain/自适应](#domain)

### [22. 对比学习(Contrastive Learning)](#ContrastiveLearning)

### [暂无分类](#100)



<br><br>

<a name="detection"/> 

## 检测


<a name="IOD"/> 

### 图像目标检测(Image Object Detection)


7. Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection(小样本目标检测的语义关系推理)<br>
[paper](https://arxiv.org/abs/2103.01903)<br><br>

6. General Instance Distillation for Object Detection(通用实例蒸馏技术在目标检测中的应用)<br>
[paper](https://arxiv.org/abs/2103.02340)<br><br>

5. Instance Localization for Self-supervised Detection Pretraining(自监督检测预训练的实例定位)<br>
[paper](https://arxiv.org/pdf/2102.08318.pdf)｜[code](https://github.com/limbo0000/InstanceLoc)<br><br>

4. Multiple Instance Active Learning for Object Detection（用于对象检测的多实例主动学习）<br>
[paper](https://github.com/yuantn/MIAL/raw/master/paper.pdf)|[code](https://github.com/yuantn/MIAL)<br><br>

3. Towards Open World Object Detection(开放世界中的目标检测)<br>
[paper](Towards Open World Object Detection)|[code](https://github.com/JosephKJ/OWOD)<br><br>

2. Positive-Unlabeled Data Purification in the Wild for Object Detection(野外检测对象的阳性无标签数据提纯)<br><br>

1. UP-DETR: Unsupervised Pre-training for Object Detection with Transformers<br>
[paper](https://arxiv.org/pdf/2011.09094.pdf)<br>
解读：[无监督预训练检测器](https://www.zhihu.com/question/432321109/answer/1606004872)<br><br>


<a name="VOD"/> 

### 视频目标检测(Video Object Detection)

3. Depth from Camera Motion and Object Detection(相机运动和物体检测的深度)<br>
[paper](https://arxiv.org/abs/2103.01468)<br><br>

2. There is More than Meets the Eye: Self-Supervised Multi-Object Detection  and Tracking with Sound by Distilling Multimodal Knowledge(多模态知识提取的自监督多目标检测与有声跟踪)<br>
[paper](https://arxiv.org/abs/2103.01353)|[video](https://www.youtube.com/channel/UCRpM8k1GY3kD2TqCo_yKN3g)|[project](http://rl.uni-freiburg.de/research/multimodal-distill)<br><br>

1. Dogfight: Detecting Drones from Drone Videos（从无人机视频中检测无人机）<br><br>
<a name="3DOD"/> 

### 三维目标检测(3D object detection)

1. Categorical Depth Distribution Network for Monocular 3D Object Detection(用于单目三维目标检测的分类深度分布网络)<br>
[paper](https://arxiv.org/abs/2103.01100)<br><br>

<a name="Activity Detection"/> 

### 动作检测(Activity Detection)

1. Coarse-Fine Networks for Temporal Activity Detection in Videos<br>
[paper](https://arxiv.org/abs/2103.01302)<br><br>

<a name="AnomallyDetetionn"/> 

### 异常检测(Anomally Detetion)

1. Multiresolution Knowledge Distillation for Anomaly Detection(用于异常检测的多分辨率知识蒸馏)<br>
[paper](https://arxiv.org/abs/2011.11108)<br><br>

<br>

<a name="ImageSegmentation"/> 

## 图像分割(Image Segmentation)

1. PointFlow: Flowing Semantics Through Points for Aerial Image Segmentation(语义流经点以进行航空图像分割)<br><br>

<a name="PanopticSegmentation"/> 

### 全景分割(Panoptic Segmentation)

2. Cross-View Regularization for Domain Adaptive Panoptic Segmentation(用于域自适应全景分割的跨视图正则化)<br>
[paper](https://arxiv.org/abs/2103.02584)<br><br>

1. 4D Panoptic LiDAR Segmentation（4D全景LiDAR分割）<br>
[paper](https://arxiv.org/abs/2102.12472)<br><br>

<a name="SemanticSegmentation"/> 

### 语义分割(Semantic Segmentation)

1. PLOP: Learning without Forgetting for Continual Semantic Segmentation（PLOP：学习而不会忘记连续的语义分割）<br>
[paper](https://arxiv.org/abs/2011.11390)<br><br>

<a name="InstanceSegmentation"/> 

### 实例分割(Instance Segmentation)

1. End-to-End Video Instance Segmentation with Transformers(使用Transformer的端到端视频实例分割) <br>
[paper](https://arxiv.org/abs/2011.14503)
<br><br>

<a name="Matting"/> 

## 抠图(Matting)

1. Real-Time High Resolution Background Matting<br>
[paper](https://arxiv.org/abs/2012.07810)|[code](https://github.com/PeterL1n/BackgroundMattingV2)|[project](https://grail.cs.washington.edu/projects/background-matting-v2/)|[video](https://youtu.be/oMfPTeYDF9g)<br><br>

<a name="HumanPoseEstimation"/> 

## 人体姿态估计(Human Pose Estimation)

3. GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation<br>
[paper](http://arxiv.org/abs/2102.12145)|[code](https://github.com/THU-DA-6D-Pose-Group/GDR-Net)<br><br>

2. CanonPose: Self-supervised Monocular 3D Human Pose Estimation in the Wild（野外自监督的单眼3D人类姿态估计）<br><br>

1. PCLs: Geometry-aware Neural Reconstruction of 3D Pose with Perspective Crop Layers（具有透视作物层的3D姿势的几何感知神经重建）<br>
[paper](https://arxiv.org/abs/2011.13607)<br><br>

<br>

<a name="ImageProcessing"/> 

## 图像处理(Image Processing)



<a name="ImageRestoration"/> 

###  图像复原(Image Restoration)/超分辨率(Super Resolution)



3. Multi-Stage Progressive Image Restoration(多阶段渐进式图像复原)<br>
[paper](https://arxiv.org/abs/2102.02808)|[code](https://github.com/swz30/MPRNet)<br><br>

2. Data-Free Knowledge Distillation For Image Super-Resolution(DAFL算法的SR版本)<br><br>

1. AdderSR: Towards Energy Efficient Image Super-Resolution(将加法网路应用到图像超分辨率中)<br>
[paper](https://arxiv.org/pdf/2009.08891.pdf)|[code](https://github.com/huawei-noah/AdderNet)<br>
解读：[华为开源加法神经网络](https://zhuanlan.zhihu.com/p/113536045)<br><br>




<a name="ISR"/> 

### 图像阴影去除(Image Shadow Removal)

1. Auto-Exposure Fusion for Single-Image Shadow Removal(用于单幅图像阴影去除的自动曝光融合)<br>
[paper](https://arxiv.org/abs/2103.01255)|[code](https://github.com/tsingqguo/exposure-fusion-shadow-removal)<br><br>



<a name="ImageDenoising"/> 

### 图像去噪/去模糊/去雨去雾(Image Denoising)

1. DeFMO: Deblurring and Shape Recovery of Fast Moving Objects(快速移动物体的去模糊和形状恢复)
[paper](https://arxiv.org/abs/2012.00595)|[code](https://github.com/rozumden/DeFMO)|[video](https://www.youtube.com/watch?v=pmAynZvaaQ4)<br><br>

<a name="ImageEdit"/> 

### 图像编辑(Image Edit)

1. Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing（利用GAN中潜在的空间维度进行实时图像编辑）<br><br>



<a name="ImageTranslation"/> 

### 图像翻译（Image Translation）


2. Image-to-image Translation via Hierarchical Style Disentanglement<br>
[paper](https://arxiv.org/abs/2103.01456)|[code](https://github.com/imlixinyang/HiSD)<br><br>

1. Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation(样式编码：用于图像到图像翻译的StyleGAN编码器)<br>
[paper](https://arxiv.org/abs/2008.00951)|[code](https://github.com/eladrich/pixel2style2pixel)|[project](https://eladrich.github.io/pixel2style2pixel/)<br><br>

<br>

<a name="Face"/> 

## 人脸(Face)

5. Cross Modal Focal Loss for RGBD Face Anti-Spoofing(Cross Modal Focal Loss for RGBD Face Anti-Spoofing)
[paper](https://arxiv.org/abs/2103.00948)<br><br>

4. When Age-Invariant Face Recognition Meets Face Age Synthesis: A  Multi-Task Learning Framework(当年龄不变的人脸识别遇到人脸年龄合成时：一个多任务学习框架)<br>
[paper](https://arxiv.org/abs/2103.01520)|[code](https://github.com/Hzzone/MTLFace)<br><br>

3. Multi-attentional Deepfake Detection(多注意的深伪检测)<br>
[paper](https://arxiv.org/abs/2103.02406)<br><br>

2. Image-to-image Translation via Hierarchical Style Disentanglement<br>
[paper](https://arxiv.org/abs/2103.01456)|[code](https://github.com/imlixinyang/HiSD)<br><br>

1. A 3D GAN for Improved Large-pose Facial Recognition(用于改善大姿势面部识别的3D GAN)<br>
[paper](https://arxiv.org/pdf/2012.10545.pdf)<br><br>

<br>

<a name="ObjectTracking"/> 

## 目标跟踪(Object Tracking)

2. Probabilistic Tracklet Scoring and Inpainting for Multiple Object Tracking(多目标跟踪的概率小波计分和修复)<br>
[paper](https://arxiv.org/abs/2012.02337)<br><br>

1. Rotation Equivariant Siamese Networks for Tracking（旋转等距连体网络进行跟踪）<br>
[paper](https://arxiv.org/abs/2012.13078)<br><br>


<br>

<a name="Re-Identification"/> 

## 重识别

1. Meta Batch-Instance Normalization for Generalizable Person Re-Identification(通用批处理人员重新标识的元批实例规范化)<br>
[paper](https://arxiv.org/abs/2011.14670)<br><br>

2. Learning to Generalize Unseen Domains via Memory-based Multi-Source Meta-Learning for Person Re-Identification (通过基于记忆模块的元学习实现多源行人再识别泛化)<br>
[paper](https://arxiv.org/abs/2012.00417)<br><br>

<br>

<a name="MedicalImaging"/> 

## 医学影像(Medical Imaging)

4. Multi-institutional Collaborations for Improving Deep Learning-based Magnetic Resonance Image Reconstruction Using Federated Learning(多机构协作改进基于深度学习的联合学习磁共振图像重建)<br>
[paper](https://arxiv.org/abs/2103.02148)|[code](https://github.com/guopengf/FLMRCM)<br><br>

3. 3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management(用于胰腺肿块分割，诊断和定量患者管理的3D图形解剖学几何集成网络)<br><br>

2. Deep Lesion Tracker: Monitoring Lesions in 4D Longitudinal Imaging Studies(深部病变追踪器：在4D纵向成像研究中监控病变)<br>
[paper](https://arxiv.org/abs/2012.04872)<br><br>

1. Automatic Vertebra Localization and Identification in CT by Spine Rectification and Anatomically-constrained Optimization(通过脊柱矫正和解剖学约束优化在CT中自动进行椎骨定位和识别)<br>
[paper](https://arxiv.org/abs/2012.07947)<br><br>

<br>

<a name="NAS"/> 

## 神经网络架构搜索(NAS)

3. AttentiveNAS: Improving Neural Architecture Search via Attentive(通过注意力改善神经架构搜索) <br>
[paper](https://arxiv.org/pdf/2011.09011.pdf)<br><br>

2. ReNAS: Relativistic Evaluation of Neural Architecture Search(NAS predictor当中ranking loss的重要性)<br>
[paper](https://arxiv.org/pdf/1910.01523.pdf)<br><br>

1. HourNAS: Extremely Fast Neural Architecture Search Through an Hourglass Lens（降低NAS的成本）<br>
[paper](https://arxiv.org/pdf/2005.14446.pdf)<br><br>

<br>

<a name="GAN"/> 

## GAN/生成式/对抗式(GAN/Generative/Adversarial)

4. Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing（利用GAN中潜在的空间维度进行实时图像编辑）<br><br>

3. Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs(Hijack-GAN：意外使用经过预训练的黑匣子GAN)<br>
[paper](https://arxiv.org/pdf/2011.14107.pdf)<br><br>

2. Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation(样式编码：用于图像到图像翻译的StyleGAN编码器)<br>
[paper](https://arxiv.org/abs/2008.00951)|[code](https://github.com/eladrich/pixel2style2pixel)|[project](https://eladrich.github.io/pixel2style2pixel/)<br><br>

1. A 3D GAN for Improved Large-pose Facial Recognition(用于改善大姿势面部识别的3D GAN)<br>
[paper](https://arxiv.org/pdf/2012.10545.pdf)<br><br>

<br>

<a name="3DVision"/> 

## 三维视觉(3D Vision)

2. A Deep Emulator for Secondary Motion of 3D Characters(三维角色二次运动的深度仿真器)
[paper](https://arxiv.org/abs/2103.01261)

1. 3D CNNs with Adaptive Temporal Feature Resolutions(具有自适应时间特征分辨率的3D CNN)<br>
[paper](https://arxiv.org/abs/2011.08652)<br><br>

<a name="3DPC"/> 

### 三维点云(3D Point Cloud)

3. Diffusion Probabilistic Models for 3D Point Cloud Generation(三维点云生成的扩散概率模型)<br>
[paper](https://arxiv.org/abs/2103.01458)|[code](https://github.com/luost26/diffusion-point-cloud)<br><br>

2. Style-based Point Generator with Adversarial Rendering for Point Cloud Completion(用于点云补全的对抗性渲染基于样式的点生成器)<br>
[paper](https://arxiv.org/abs/2103.02535)

1. PREDATOR: Registration of 3D Point Clouds with Low Overlap(预测器：低重叠的3D点云的注册)<br>
[paper](https://arxiv.org/pdf/2011.13005.pdf)|[code](https://github.com/ShengyuH/OverlapPredator)|[project](https://overlappredator.github.io/)<br><br>


<a name="3DReconstruction"/> 

### 三维重建(3D Reconstruction)

1. PCLs: Geometry-aware Neural Reconstruction of 3D Pose with Perspective Crop Layers（具有透视作物层的3D姿势的几何感知神经重建）<br>
[paper](https://arxiv.org/abs/2011.13607)<br><br>

<br>

<a name="ModelCompression"/> 

## 模型压缩(Model Compression)

2. Manifold Regularized Dynamic Network Pruning（动态剪枝的过程中考虑样本复杂度与网络复杂度的约束）<br><br>

1. Learning Student Networks in the Wild（一种不需要原始训练数据的模型压缩和加速技术）<br>
[paper](https://arxiv.org/pdf/1904.01186.pdf)|[code](https://github.com/huawei-noah/DAFL)<br>
解读：[华为诺亚方舟实验室提出无需数据网络压缩技术](https://zhuanlan.zhihu.com/p/81277796)<br><br>

<a name="KnowledgeDistillation"/> 

### 知识蒸馏(Knowledge Distillation)

3. General Instance Distillation for Object Detection(通用实例蒸馏技术在目标检测中的应用)<br>
[paper](https://arxiv.org/abs/2103.02340)<br><br>

2. Multiresolution Knowledge Distillation for Anomaly Detection(用于异常检测的多分辨率知识蒸馏)<br>
[paper](https://arxiv.org/abs/2011.11108)<br><br>

1. Distilling Object Detectors via Decoupled Features（前景背景分离的蒸馏技术） <br><br>

<br>

<a name="NNS"/> 

## 神经网络架构(Neural Network Structure)

Rethinking Channel Dimensions for Efficient Model Design(重新考虑通道尺寸以进行有效的模型设计)<br>
[paper](https://arxiv.org/abs/2007.00992)|[code](https://github.com/clovaai/rexnet)<br><br>

Inverting the Inherence of Convolution for Visual Recognition（颠倒卷积的固有性以进行视觉识别）<br><br>

RepVGG: Making VGG-style ConvNets Great Again<br>
[paper](https://arxiv.org/abs/2101.03697)|[code](https://github.com/megvii-model/RepVGG)<br>
解读：[RepVGG：极简架构，SOTA性能，让VGG式模型再次伟大](https://zhuanlan.zhihu.com/p/344324470)<br><br>

<a name="Transformer"/> 

### Transformer

Transformer Interpretability Beyond Attention Visualization(注意力可视化之外的Transformer可解释性)<br>
[paper](https://arxiv.org/pdf/2012.09838.pdf)|[code](https://github.com/hila-chefer/Transformer-Explainability)<br><br>

UP-DETR: Unsupervised Pre-training for Object Detection with Transformers<br>
[paper](https://arxiv.org/pdf/2011.09094.pdf)<br>
解读：[无监督预训练检测器](https://www.zhihu.com/question/432321109/answer/1606004872)<br><br>

Pre-Trained Image Processing Transformer(底层视觉预训练模型)<br>
[paper](https://arxiv.org/pdf/2012.00364.pdf)<br><br>

<a name="GNN"/> 

### 图神经网络(GNN)

Sequential Graph Convolutional Network for Active Learning(主动学习的顺序图卷积网络)<br>
[paper](https://arxiv.org/pdf/2006.10219.pdf)<br><br>


<br>

<a name="DataProcessing"/> 

## 数据处理(Data Processing)

<a name="DataAugmentation"/> 

### 数据增广(Data Augmentation)

1. KeepAugment: A Simple Information-Preserving Data Augmentation(一种简单的保存信息的数据扩充)<br>
[paper](https://arxiv.org/pdf/2011.11778.pdf)<br><br>

<a name="BatchNormalization"/> 

### 归一化/正则化(Batch Normalization)

3. Adaptive Consistency Regularization for Semi-Supervised Transfer Learning(半监督转移学习的自适应一致性正则化)<br>
[paper](https://arxiv.org/abs/2103.02193)|[code](https://github.com/SHI-Labs/Semi-Supervised-Transfer-Learning)

2. Meta Batch-Instance Normalization for Generalizable Person Re-Identification(通用批处理人员重新标识的元批实例规范化)<br>
[paper](https://arxiv.org/abs/2011.14670)<br><br>

1. Representative Batch Normalization with Feature Calibration（具有特征校准功能的代表性批量归一化）<br><br>

<a name="ImageClustering"/> 

### 图像聚类(Image Clustering)

2. Improving Unsupervised Image Clustering With Robust Learning（通过鲁棒学习改善无监督图像聚类）<br>
[paper](https://arxiv.org/abs/2012.11150)|[code](https://github.com/deu30303/RUC)<br><br>

1. Reconsidering Representation Alignment for Multi-view Clustering(重新考虑多视图聚类的表示对齐方式)<br><br>

<br>

<a name="ModelEvaluation"/> 

## 模型评估(Model Evaluation)

1. Are Labels Necessary for Classifier Accuracy Evaluation?(测试集没有标签，我们可以拿来测试模型吗？)<br>
[paper](https://arxiv.org/abs/2007.02915)|[解读](https://zhuanlan.zhihu.com/p/328686799)<br><br>


<br>

<a name="Database"/> 

## 数据集(Database)

1. Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels（重新标记ImageNet：从单标签到多标签，从全局标签到本地标签）<br>
[paper](https://arxiv.org/abs/2101.05022)|[code](https://github.com/naver-ai/relabel_imagenet)<br><br>

<br>

<a name="ActiveLearning"/> 

## 主动学习(Active Learning)


3. Vab-AL: Incorporating Class Imbalance and Difficulty with Variational Bayes for Active Learning<br>
[paper](https://github.com/yuantn/MIAL/raw/master/paper.pdf)|[code](https://github.com/yuantn/MIAL)<br><br>

2. Multiple Instance Active Learning for Object Detection（用于对象检测的多实例主动学习）<br>
[paper](https://github.com/yuantn/MIAL/raw/master/paper.pdf)|[code](https://github.com/yuantn/MIAL)<br><br>

1. Sequential Graph Convolutional Network for Active Learning(主动学习的顺序图卷积网络)<br>
[paper](https://arxiv.org/pdf/2006.10219.pdf)<br><br>

<br>

<a name="Few-shotLearning"/> 

## 小样本学习(Few-shot Learning)/零样本

4. Counterfactual Zero-Shot and Open-Set Visual Recognition(反事实零射和开集视觉识别)<br>
[paper](https://arxiv.org/abs/2103.00887)|[code](https://github.com/yue-zhongqi/gcm-cf)<br><br>

3. Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection(小样本目标检测的语义关系推理)<br>
[paper](https://arxiv.org/abs/2103.01903)<br><br>

2. Few-shot Open-set Recognition by Transformation Consistency(转换一致性很少的开放集识别)<br><br>

1. Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning(探索少量学习的不变表示形式和等变表示形式的互补强度)<br>
[paper](https://arxiv.org/abs/2103.01315)|<br>

<br>

<a name="ContinualLearning"/> 

## 持续学习(Continual Learning/Life-long Learning)

Rainbow Memory: Continual Learning with a Memory of Diverse Samples（不断学习与多样本的记忆）<br><br>

Learning the Superpixel in a Non-iterative and Lifelong Manner(以非迭代和终身的方式学习超像素)<br><br>


<br><br>

<a name="VisualReasoning"/> 

## 视觉推理(Visual Reasoning)

1. Transformation Driven Visual Reasoning(转型驱动的视觉推理)<br>
[paper](https://arxiv.org/pdf/2011.13160.pdf)|[code](https://github.com/hughplay/TVR)|[project](https://hongxin2019.github.io/TVR/)<br>


<br><br>

<a name="domain"/> 

## 迁移学习/domain/自适应](#domain)

4. Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning(通过域随机化和元学习对视觉表示进行连续调整)<br>
[paper](https://arxiv.org/abs/2012.04324)<br><br>

3. Domain Generalization via Inference-time Label-Preserving Target Projections(基于推理时间保标目标投影的区域泛化)<br>
[paper](https://arxiv.org/abs/2103.01134)<br><br>

2. MetaSCI: Scalable and Adaptive Reconstruction for Video Compressive  Sensing(可伸缩的自适应视频压缩传感重建)<br>
[paper](https://arxiv.org/abs/2103.01786)|[code](https://github.com/xyvirtualgroup/MetaSCI-CVPR2021)<br><br>

1. FSDR: Frequency Space Domain Randomization for Domain Generalization(用于域推广的频域随机化)<br>
[paper](https://arxiv.org/abs/2103.02370)<br><br>

<br><br>

<a name="ContrastiveLearning)"/> 

## 对比学习(Contrastive Learning)

1. Fine-grained Angular Contrastive Learning with Coarse Labels(粗标签的细粒度角度对比学习)<br>
[paper](https://arxiv.org/abs/2012.03515)<br><br>

<br><br>

<a name="100"/> 

## 暂无分类

Scan2Cap: Context-aware Dense Captioning in RGB-D Scans(【图像字幕】Scan2Cap：RGB-D扫描中的上下文感知密集字幕)
[paper](https://arxiv.org/abs/2012.02206)|[code](https://github.com/daveredrum/Scan2Cap)|[project](https://daveredrum.github.io/Scan2Cap/)|[video](https://youtu.be/AgmIpDbwTCY)<br><br>

Hierarchical and Partially Observable Goal-driven Policy Learning with  Goals Relational Graph(基于目标关系图的分层部分可观测目标驱动策略学习)<br>
[paper](https://arxiv.org/abs/2103.01350)<br><br>

ID-Unet: Iterative Soft and Hard Deformation for View Synthesis(视图合成的迭代软硬变形)<br>
[paper](https://arxiv.org/abs/2103.02264)<br><br>

PML: Progressive Margin Loss for Long-tailed Age Classification(【长尾分布】【图像分类】长尾年龄分类的累进边际损失)<br>
[paper](https://arxiv.org/abs/2103.02140)<br><br>

Diversifying Sample Generation for Data-Free Quantization（【图像生成】多样化的样本生成，实现无数据量化）<br>
[paper](https://arxiv.org/abs/2103.01049)<br><br>

Domain Generalization via Inference-time Label-Preserving Target Projections（通过保留推理时间的目标投影进行域泛化）<br>
[paper](https://arxiv.org/pdf/2103.01134.pdf)<br><br>

DeRF: Decomposed Radiance Fields（分解的辐射场）<br>
[project](https://ubc-vision.github.io/derf/)<br><br>

Densely connected multidilated convolutional networks for dense prediction tasks（【密集预测】密集连接的多重卷积网络，用于密集的预测任务）<br>
[paper](https://arxiv.org/abs/2011.11844)<br><br>

VirTex: Learning Visual Representations from Textual Annotations（【表示学习】从文本注释中学习视觉表示）<br>
[paper](https://arxiv.org/abs/2006.06666)|[code](https://github.com/kdexd/virtex)<br><br>

Weakly-supervised Grounded Visual Question Answering using Capsules（使用胶囊进行弱监督的地面视觉问答）<br><br>

FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation（【视频插帧】FLAVR：用于快速帧插值的与流无关的视频表示）<br>
[paper](https://arxiv.org/pdf/2012.08512.pdf)|[code](https://tarun005.github.io/FLAVR/Code)|[project](https://tarun005.github.io/FLAVR/)<br><br>

Probabilistic Embeddings for Cross-Modal Retrieval（跨模态检索的概率嵌入）<br>
[paper](https://arxiv.org/abs/2101.05068)<br><br>

Self-supervised Simultaneous Multi-Step Prediction of Road Dynamics and Cost Map(道路动力学和成本图的自监督式多步同时预测)<br><br>

IIRC: Incremental Implicitly-Refined Classification(增量式隐式定义的分类)<br>
[paper](https://arxiv.org/abs/2012.12477)|[project](https://chandar-lab.github.io/IIRC/)<br><br>

Fair Attribute Classification through Latent Space De-biasing(通过潜在空间去偏的公平属性分类)<br>
[paper](https://arxiv.org/abs/2012.01469)|[code](https://github.com/princetonvisualai/gan-debiasing)|[project](https://princetonvisualai.github.io/gan-debiasing/)<br><br>

Information-Theoretic Segmentation by Inpainting Error Maximization(修复误差最大化的信息理论分割)<br>
[paper](https://arxiv.org/abs/2012.07287)<br><br>

UC2: Universal Cross-lingual Cross-modal Vision-and-Language Pretraining(【视频语言学习】UC2：通用跨语言跨模态视觉和语言预培训)<br><br>

Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling(通过稀疏采样进行视频和语言学习)<br>
[paper](https://arxiv.org/pdf/2102.06183.pdf)|[code](https://github.com/jayleicn/ClipBERT)<br><br>

D-NeRF: Neural Radiance Fields for Dynamic Scenes(D-NeRF：动态场景的神经辐射场)<br>
[paper](https://arxiv.org/abs/2011.13961)|[project](https://www.albertpumarola.com/research/D-NeRF/index.html)<br><br>

Weakly Supervised Learning of Rigid 3D Scene Flow(刚性3D场景流的弱监督学习)<br>
[paper](https://arxiv.org/pdf/2102.08945.pdf)|[code](https://arxiv.org/pdf/2102.08945.pdf)|[project](https://3dsceneflow.github.io/)<br><br>

<br>

<a name="2"/> 

## 2. CVPR2021 Oral

14. PatchmatchNet: Learned Multi-View Patchmatch Stereo(学习多视图立体声)<br>
[paper](https://arxiv.org/abs/2012.01411)|[code](https://github.com/FangjinhuaWang/PatchmatchNet)

13. Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning(通过域随机化和元学习对视觉表示进行连续调整)<br>
[paper](https://arxiv.org/abs/2012.04324)<br><br>

12. Single-Stage Instance Shadow Detection with Bidirectional Relation Learning(具有双向关系学习的单阶段实例阴影检测)<br><br>

11. Neural Geometric Level of Detail:Real-time Rendering with Implicit 3D Surfaces(神经几何细节水平：隐式3D曲面的实时渲染)<br>
[paper](https://arxiv.org/abs/2101.10994)|[code](https://github.com/nv-tlabs/nglod)|[project](https://nv-tlabs.github.io/nglod/)<br><br>

9. PREDATOR: Registration of 3D Point Clouds with Low Overlap(预测器：低重叠的3D点云的注册)<br>
[paper](https://arxiv.org/pdf/2011.13005.pdf)|[code](https://github.com/ShengyuH/OverlapPredator)|[project](https://overlappredator.github.io/)<br><br>

8. Domain Generalization via Inference-time Label-Preserving Target Projections(通过保留推理时间的目标投影进行域泛化)<br>
[paper](https://arxiv.org/abs/2103.01134)<br><br>

7. Neural Deformation Graphs for Globally-consistent Non-rigid Reconstruction(全局一致的非刚性重建的神经变形图)<br>
[paper](https://arxiv.org/abs/2012.01451)|[project](https://aljazbozic.github.io/neural_deformation_graphs/)<br><br>

6. Fine-grained Angular Contrastive Learning with Coarse Labels(粗标签的细粒度角度对比学习)<br>
[paper](https://arxiv.org/abs/2012.03515)<br><br>

5. Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling(T通过稀疏采样进行视频和语言学习)<br>
[paper](https://arxiv.org/pdf/2102.06183.pdf)|[code](https://github.com/jayleicn/ClipBERT)<br><br>

4. Cross-View Regularization for Domain Adaptive Panoptic Segmentation(用于域自适应全景分割的跨视图正则化)<br>
[paper](https://arxiv.org/abs/2103.02584)<br><br>

3. Image-to-image Translation via Hierarchical Style Disentanglement(通过分层样式分解实现图像到图像的翻译)<br>
[paper](https://arxiv.org/abs/2103.01456)|[code](https://github.com/imlixinyang/HiSD)<br><br>

2. Towards Open World Object Detection(开放世界中的目标检测)<br>
[paper](Towards Open World Object Detection)|[code](https://github.com/JosephKJ/OWOD)<br><br>

1. End-to-End Video Instance Segmentation with Transformers(使用Transformer的端到端视频实例分割) <br>
[paper](https://arxiv.org/abs/2011.14503)<br><br>

<br>

<a name="3"/> 

## 3. To do list

* CVPR2021论文解读
* CVPR2021论文分享
